{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "toxim\n",
    "deeptox\n",
    "\n",
    "kaggel par bhi he ek \n",
    "https://github.com/masashitsubaki/molecularGNN_smiles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resnet vs MobileNet "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "import tensorflow.keras.layers as layers\n",
    "import tensorflow.keras.optimizers as optim\n",
    "import tensorflow.keras.models as models\n",
    "import tensorflow.keras.preprocessing as prepro\n",
    "import tensorflow.keras.losses as loss\n",
    "from tensorflow_addons.losses import SigmoidFocalCrossEntropy as focal_loss\n",
    "\n",
    "import cv2\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import json\n",
    "\n",
    "from tqdm.auto import trange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA = r\"C:\\Users\\suyash\\Desktop\\deep fake\\train_sample_videos\"\n",
    "JSON = r\"C:\\Users\\suyash\\Desktop\\deep fake\\train_sample_videos\\metadata.json\"\n",
    "\n",
    "data = open(JSON)\n",
    "dataset = json.load(data)\n",
    "data = []\n",
    "for d in dataset:\n",
    "    data.append(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ytrain = []\n",
    "for d in dataset.values():\n",
    "    for s in d.values():\n",
    "        if s == \"FAKE\":\n",
    "            ytrain.append(0)\n",
    "        else:\n",
    "            ytrain.append(1)\n",
    "        break\n",
    "y = np.array(ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400,)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(y).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09e1613358ca42e68b97c09bb2a472bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading:0/400 || Progress:   0%|                                                                              â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(184, 50, 224, 224, 3)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no_video = len(data)\n",
    "video = []\n",
    "ytrain = []\n",
    "cond = True\n",
    "load = trange(no_video, desc=f\"Loading:0/{no_video} || Progress\", unit=\"images\", ncols=1000)\n",
    "for l in load:\n",
    "    cap = cv2.VideoCapture(DATA+\"/\"+data[l])\n",
    "    v = []\n",
    "    e = 0 \n",
    "    if y[l] == 1 or l%3 == 0:\n",
    "        cond = True\n",
    "    else:\n",
    "        cond = False\n",
    "        \n",
    "    while cond:\n",
    "        ret, frame = cap.read() \n",
    "        e=e+1\n",
    "        if not ret:\n",
    "            break\n",
    "        if e%5==0:\n",
    "            frame = cv2.resize(frame, (224, 224), interpolation = cv2.INTER_AREA)/255.0\n",
    "            v.append(frame)\n",
    "        if e>250:\n",
    "            break\n",
    "            \n",
    "    if cond:\n",
    "        v = np.array(v)\n",
    "        video.append(v)\n",
    "        ytrain.append(y[l])\n",
    "\n",
    "    load.set_description(f\"Loading:{l+1}/{no_video} || Progress\", refresh=True)\n",
    "video = np.array(video)\n",
    "ytrain = np.array(ytrain)\n",
    "video.shape   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ytrain = np.array(ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(numpy.ndarray, numpy.ndarray)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(video), type(ytrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ConvLSTMBlock(x, filters, kernel=3, seq=True):\n",
    "    x = layers.ConvLSTM2D(filters, kernel, padding=\"same\", return_sequences=seq)(x)\n",
    "    x = layers.BatchNormalization(momentum=0.5)(x)\n",
    "    x = layers.ReLU()(x)\n",
    "    if seq:\n",
    "        x = layers.MaxPool3D((1,2,2))(x)\n",
    "    else:\n",
    "        x = layers.MaxPool2D((2,2))(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ConvLSTM(inp, filters):\n",
    "    inp = layers.Input(inp)\n",
    "    x = ConvLSTMBlock(inp, filters)\n",
    "    x = ConvLSTMBlock(x, filters*2)\n",
    "    x = ConvLSTMBlock(x, filters*4)\n",
    "    x = ConvLSTMBlock(x, filters*8)\n",
    "    x = ConvLSTMBlock(x, filters*16)\n",
    "    x = layers.Reshape((50, 7*7*256))(x)\n",
    "    x = layers.LSTM(256, activation=\"relu\", return_sequences=True)(x)\n",
    "    x = layers.LSTM(128, activation=\"relu\")(x)\n",
    "    x = layers.Dense(10, activation=\"relu\")(x)\n",
    "    x = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "    \n",
    "    model = models.Model(inputs=inp, outputs=x, name=\"deepfake\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"deepfake\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_12 (InputLayer)       [(None, 50, 224, 224, 3)  0         \n",
      "                             ]                                   \n",
      "                                                                 \n",
      " conv_lstm2d_53 (ConvLSTM2D)  (None, 50, 224, 224, 16)  11008    \n",
      "                                                                 \n",
      " batch_normalization_53 (Bat  (None, 50, 224, 224, 16)  64       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " re_lu_53 (ReLU)             (None, 50, 224, 224, 16)  0         \n",
      "                                                                 \n",
      " max_pooling3d_52 (MaxPoolin  (None, 50, 112, 112, 16)  0        \n",
      " g3D)                                                            \n",
      "                                                                 \n",
      " conv_lstm2d_54 (ConvLSTM2D)  (None, 50, 112, 112, 32)  55424    \n",
      "                                                                 \n",
      " batch_normalization_54 (Bat  (None, 50, 112, 112, 32)  128      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " re_lu_54 (ReLU)             (None, 50, 112, 112, 32)  0         \n",
      "                                                                 \n",
      " max_pooling3d_53 (MaxPoolin  (None, 50, 56, 56, 32)   0         \n",
      " g3D)                                                            \n",
      "                                                                 \n",
      " conv_lstm2d_55 (ConvLSTM2D)  (None, 50, 56, 56, 64)   221440    \n",
      "                                                                 \n",
      " batch_normalization_55 (Bat  (None, 50, 56, 56, 64)   256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " re_lu_55 (ReLU)             (None, 50, 56, 56, 64)    0         \n",
      "                                                                 \n",
      " max_pooling3d_54 (MaxPoolin  (None, 50, 28, 28, 64)   0         \n",
      " g3D)                                                            \n",
      "                                                                 \n",
      " conv_lstm2d_56 (ConvLSTM2D)  (None, 50, 28, 28, 128)  885248    \n",
      "                                                                 \n",
      " batch_normalization_56 (Bat  (None, 50, 28, 28, 128)  512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " re_lu_56 (ReLU)             (None, 50, 28, 28, 128)   0         \n",
      "                                                                 \n",
      " max_pooling3d_55 (MaxPoolin  (None, 50, 14, 14, 128)  0         \n",
      " g3D)                                                            \n",
      "                                                                 \n",
      " conv_lstm2d_57 (ConvLSTM2D)  (None, 50, 14, 14, 256)  3539968   \n",
      "                                                                 \n",
      " batch_normalization_57 (Bat  (None, 50, 14, 14, 256)  1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " re_lu_57 (ReLU)             (None, 50, 14, 14, 256)   0         \n",
      "                                                                 \n",
      " max_pooling3d_56 (MaxPoolin  (None, 50, 7, 7, 256)    0         \n",
      " g3D)                                                            \n",
      "                                                                 \n",
      " reshape_8 (Reshape)         (None, 50, 12544)         0         \n",
      "                                                                 \n",
      " lstm_7 (LSTM)               (None, 50, 256)           13108224  \n",
      "                                                                 \n",
      " lstm_8 (LSTM)               (None, 128)               197120    \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 10)                1290      \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 1)                 11        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 18,021,717\n",
      "Trainable params: 18,020,725\n",
      "Non-trainable params: 992\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = ConvLSTM((50, 224, 224, 3), 16)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\suyash\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\optimizer_v2\\adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "The Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "model.compile(optimizer=optim.Adam(lr=0.001), loss=loss.BinaryCrossentropy(), metrics=\"accuracy\" )\n",
    "model.fit(video[:150], ytrain[:150], batch_size=5, epochs=3, verbose=1, validation_data=(video[150:], ytrain[150:]), validation_batch_size=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"./meop.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "cabed6552182076907bfdc495182d8bb0133da97d0d21fa33aa63cdbe2263e8f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
